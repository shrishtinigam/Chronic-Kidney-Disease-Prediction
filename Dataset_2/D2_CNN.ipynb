{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "D2_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Convolutional Neural Network on Dataset - 2"
      ],
      "metadata": {
        "id": "uP0vPIRoeNhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRS5YV2QeMoG",
        "outputId": "a3146800-642a-4302-d679-71f2e57663de",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! head dataset_2_preprocessed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExSdb-4gegOw",
        "outputId": "3e43f3de-02d8-4198-93a2-bc883776831d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "head: cannot open 'dataset_2_preprocessed' for reading: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3I-cjP-TNcN1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/dataset_2_preprocessed.csv')\n",
        "df = df.drop(columns=['id'])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "IVtHL3rFN6vk",
        "outputId": "fe702599-7bca-4395-ff07-3dd3a66acbac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     age   bp      sg   al   su  rbc  pc  pcc  ba    bgr  ...   pcv     wc  \\\n",
              "0     62   70  1.0250  3.0  0.0    1   1    1   1  122.0  ...  39.0   7900   \n",
              "1     54   70  1.0150  0.0  0.0    1   0    1   1  233.0  ...  42.0  10600   \n",
              "2     47   80  1.0175  1.0  0.0    1   0    1   1  114.0  ...  37.0   6750   \n",
              "3     43   60  1.0250  0.0  0.0    1   0    1   1  108.0  ...  43.0   7200   \n",
              "4     42  100  1.0150  4.0  0.0    1   1    1   0  293.5  ...  39.0   8300   \n",
              "..   ...  ...     ...  ...  ...  ...  ..  ...  ..    ...  ...   ...    ...   \n",
              "257   46   60  1.0100  1.0  0.0    1   0    1   1  163.0  ...  28.0  14600   \n",
              "258   50   90  1.0200  1.5  1.0    1   0    1   1   89.0  ...  17.0   6500   \n",
              "259   23   80  1.0250  0.0  0.0    1   0    1   1  111.0  ...  41.0   7200   \n",
              "260   38   80  1.0200  0.0  0.0    1   0    1   1   99.0  ...  44.0   7300   \n",
              "261   17   60  1.0100  0.0  0.0    1   0    1   1   92.0  ...  52.0   7000   \n",
              "\n",
              "       rc  htn  dm  cad  appet  pe  ane  classification  \n",
              "0    3.90    0   0    1      0   1    1               0  \n",
              "1    5.15    1   0    1      0   1    1               0  \n",
              "2    4.30    0   1    1      1   1    1               0  \n",
              "3    5.50    1   1    1      0   1    1               1  \n",
              "4    4.60    0   1    1      1   1    1               0  \n",
              "..    ...  ...  ..  ...    ...  ..  ...             ...  \n",
              "257  3.20    0   0    1      0   1    1               0  \n",
              "258  4.20    0   0    1      0   0    0               0  \n",
              "259  5.00    1   1    1      0   1    1               1  \n",
              "260  6.40    1   1    1      0   1    1               1  \n",
              "261  5.30    1   1    1      0   1    1               0  \n",
              "\n",
              "[262 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0a49b5cb-7904-4e21-81fc-7d388bf012f9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bp</th>\n",
              "      <th>sg</th>\n",
              "      <th>al</th>\n",
              "      <th>su</th>\n",
              "      <th>rbc</th>\n",
              "      <th>pc</th>\n",
              "      <th>pcc</th>\n",
              "      <th>ba</th>\n",
              "      <th>bgr</th>\n",
              "      <th>...</th>\n",
              "      <th>pcv</th>\n",
              "      <th>wc</th>\n",
              "      <th>rc</th>\n",
              "      <th>htn</th>\n",
              "      <th>dm</th>\n",
              "      <th>cad</th>\n",
              "      <th>appet</th>\n",
              "      <th>pe</th>\n",
              "      <th>ane</th>\n",
              "      <th>classification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>62</td>\n",
              "      <td>70</td>\n",
              "      <td>1.0250</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>122.0</td>\n",
              "      <td>...</td>\n",
              "      <td>39.0</td>\n",
              "      <td>7900</td>\n",
              "      <td>3.90</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>54</td>\n",
              "      <td>70</td>\n",
              "      <td>1.0150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>233.0</td>\n",
              "      <td>...</td>\n",
              "      <td>42.0</td>\n",
              "      <td>10600</td>\n",
              "      <td>5.15</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>47</td>\n",
              "      <td>80</td>\n",
              "      <td>1.0175</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>114.0</td>\n",
              "      <td>...</td>\n",
              "      <td>37.0</td>\n",
              "      <td>6750</td>\n",
              "      <td>4.30</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43</td>\n",
              "      <td>60</td>\n",
              "      <td>1.0250</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>108.0</td>\n",
              "      <td>...</td>\n",
              "      <td>43.0</td>\n",
              "      <td>7200</td>\n",
              "      <td>5.50</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>42</td>\n",
              "      <td>100</td>\n",
              "      <td>1.0150</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>293.5</td>\n",
              "      <td>...</td>\n",
              "      <td>39.0</td>\n",
              "      <td>8300</td>\n",
              "      <td>4.60</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>46</td>\n",
              "      <td>60</td>\n",
              "      <td>1.0100</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>163.0</td>\n",
              "      <td>...</td>\n",
              "      <td>28.0</td>\n",
              "      <td>14600</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>50</td>\n",
              "      <td>90</td>\n",
              "      <td>1.0200</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>89.0</td>\n",
              "      <td>...</td>\n",
              "      <td>17.0</td>\n",
              "      <td>6500</td>\n",
              "      <td>4.20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>23</td>\n",
              "      <td>80</td>\n",
              "      <td>1.0250</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>111.0</td>\n",
              "      <td>...</td>\n",
              "      <td>41.0</td>\n",
              "      <td>7200</td>\n",
              "      <td>5.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>38</td>\n",
              "      <td>80</td>\n",
              "      <td>1.0200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>99.0</td>\n",
              "      <td>...</td>\n",
              "      <td>44.0</td>\n",
              "      <td>7300</td>\n",
              "      <td>6.40</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>17</td>\n",
              "      <td>60</td>\n",
              "      <td>1.0100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>92.0</td>\n",
              "      <td>...</td>\n",
              "      <td>52.0</td>\n",
              "      <td>7000</td>\n",
              "      <td>5.30</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>262 rows × 25 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a49b5cb-7904-4e21-81fc-7d388bf012f9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0a49b5cb-7904-4e21-81fc-7d388bf012f9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0a49b5cb-7904-4e21-81fc-7d388bf012f9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "WPID-nE_e5Wg",
        "outputId": "3fa0adfc-66f2-437e-a3d2-73c294efbfa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age   bp      sg   al   su  rbc  pc  pcc  ba    bgr  ...   pcv     wc  \\\n",
              "0   62   70  1.0250  3.0  0.0    1   1    1   1  122.0  ...  39.0   7900   \n",
              "1   54   70  1.0150  0.0  0.0    1   0    1   1  233.0  ...  42.0  10600   \n",
              "2   47   80  1.0175  1.0  0.0    1   0    1   1  114.0  ...  37.0   6750   \n",
              "3   43   60  1.0250  0.0  0.0    1   0    1   1  108.0  ...  43.0   7200   \n",
              "4   42  100  1.0150  4.0  0.0    1   1    1   0  293.5  ...  39.0   8300   \n",
              "\n",
              "     rc  htn  dm  cad  appet  pe  ane  classification  \n",
              "0  3.90    0   0    1      0   1    1               0  \n",
              "1  5.15    1   0    1      0   1    1               0  \n",
              "2  4.30    0   1    1      1   1    1               0  \n",
              "3  5.50    1   1    1      0   1    1               1  \n",
              "4  4.60    0   1    1      1   1    1               0  \n",
              "\n",
              "[5 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dcc60288-7a87-4e43-a1e2-8af3239cb488\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bp</th>\n",
              "      <th>sg</th>\n",
              "      <th>al</th>\n",
              "      <th>su</th>\n",
              "      <th>rbc</th>\n",
              "      <th>pc</th>\n",
              "      <th>pcc</th>\n",
              "      <th>ba</th>\n",
              "      <th>bgr</th>\n",
              "      <th>...</th>\n",
              "      <th>pcv</th>\n",
              "      <th>wc</th>\n",
              "      <th>rc</th>\n",
              "      <th>htn</th>\n",
              "      <th>dm</th>\n",
              "      <th>cad</th>\n",
              "      <th>appet</th>\n",
              "      <th>pe</th>\n",
              "      <th>ane</th>\n",
              "      <th>classification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>62</td>\n",
              "      <td>70</td>\n",
              "      <td>1.0250</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>122.0</td>\n",
              "      <td>...</td>\n",
              "      <td>39.0</td>\n",
              "      <td>7900</td>\n",
              "      <td>3.90</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>54</td>\n",
              "      <td>70</td>\n",
              "      <td>1.0150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>233.0</td>\n",
              "      <td>...</td>\n",
              "      <td>42.0</td>\n",
              "      <td>10600</td>\n",
              "      <td>5.15</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>47</td>\n",
              "      <td>80</td>\n",
              "      <td>1.0175</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>114.0</td>\n",
              "      <td>...</td>\n",
              "      <td>37.0</td>\n",
              "      <td>6750</td>\n",
              "      <td>4.30</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43</td>\n",
              "      <td>60</td>\n",
              "      <td>1.0250</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>108.0</td>\n",
              "      <td>...</td>\n",
              "      <td>43.0</td>\n",
              "      <td>7200</td>\n",
              "      <td>5.50</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>42</td>\n",
              "      <td>100</td>\n",
              "      <td>1.0150</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>293.5</td>\n",
              "      <td>...</td>\n",
              "      <td>39.0</td>\n",
              "      <td>8300</td>\n",
              "      <td>4.60</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 25 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dcc60288-7a87-4e43-a1e2-8af3239cb488')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dcc60288-7a87-4e43-a1e2-8af3239cb488 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dcc60288-7a87-4e43-a1e2-8af3239cb488');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "bnJ_xnmyL_7a",
        "outputId": "5404c69f-eb28-442e-8c7c-5e089a4f57e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(262, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "evpLQANbfBll",
        "outputId": "6798a8bf-d4af-48c5-fde0-5c593992fd2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 262 entries, 0 to 261\n",
            "Data columns (total 25 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   age             262 non-null    int64  \n",
            " 1   bp              262 non-null    int64  \n",
            " 2   sg              262 non-null    float64\n",
            " 3   al              262 non-null    float64\n",
            " 4   su              262 non-null    float64\n",
            " 5   rbc             262 non-null    int64  \n",
            " 6   pc              262 non-null    int64  \n",
            " 7   pcc             262 non-null    int64  \n",
            " 8   ba              262 non-null    int64  \n",
            " 9   bgr             262 non-null    float64\n",
            " 10  bu              262 non-null    float64\n",
            " 11  sc              262 non-null    float64\n",
            " 12  sod             262 non-null    float64\n",
            " 13  pot             262 non-null    float64\n",
            " 14  hemo            262 non-null    float64\n",
            " 15  pcv             262 non-null    float64\n",
            " 16  wc              262 non-null    int64  \n",
            " 17  rc              262 non-null    float64\n",
            " 18  htn             262 non-null    int64  \n",
            " 19  dm              262 non-null    int64  \n",
            " 20  cad             262 non-null    int64  \n",
            " 21  appet           262 non-null    int64  \n",
            " 22  pe              262 non-null    int64  \n",
            " 23  ane             262 non-null    int64  \n",
            " 24  classification  262 non-null    int64  \n",
            "dtypes: float64(11), int64(14)\n",
            "memory usage: 51.3 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "n86s2r16fBpt",
        "outputId": "5cc39f97-939d-4a0a-9ac1-3bb016c1137a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              age          bp          sg          al          su         rbc  \\\n",
              "count  262.000000  262.000000  262.000000  262.000000  262.000000  262.000000   \n",
              "mean    52.351145   76.259542    1.017338    0.998092    0.496183    0.835878   \n",
              "std     16.570954   14.375153    0.005532    1.323598    1.060427    0.371095   \n",
              "min      6.000000   50.000000    1.005000    0.000000    0.000000    0.000000   \n",
              "25%     43.000000   70.000000    1.013125    0.000000    0.000000    1.000000   \n",
              "50%     55.000000   80.000000    1.017500    0.000000    0.000000    1.000000   \n",
              "75%     65.000000   80.000000    1.020000    2.000000    0.000000    1.000000   \n",
              "max     90.000000  180.000000    1.025000    5.000000    5.000000    1.000000   \n",
              "\n",
              "               pc         pcc          ba         bgr  ...        pcv  \\\n",
              "count  262.000000  262.000000  262.000000  262.000000  ...  262.00000   \n",
              "mean     0.244275    0.900763    0.938931  155.921756  ...   39.51145   \n",
              "std      0.430479    0.299552    0.239915   78.560435  ...    8.32378   \n",
              "min      0.000000    0.000000    0.000000   70.000000  ...    9.00000   \n",
              "25%      0.000000    1.000000    1.000000  103.250000  ...   33.25000   \n",
              "50%      0.000000    1.000000    1.000000  127.250000  ...   41.00000   \n",
              "75%      0.000000    1.000000    1.000000  177.500000  ...   45.50000   \n",
              "max      1.000000    1.000000    1.000000  490.000000  ...   54.00000   \n",
              "\n",
              "                 wc          rc         htn          dm         cad  \\\n",
              "count    262.000000  262.000000  262.000000  262.000000  262.000000   \n",
              "mean    8279.198473    4.697328    0.625954    0.633588    0.912214   \n",
              "std     2835.242178    0.923995    0.484802    0.482746    0.283525   \n",
              "min     2200.000000    2.100000    0.000000    0.000000    0.000000   \n",
              "25%     6662.500000    4.062500    0.000000    0.000000    1.000000   \n",
              "50%     7900.000000    4.800000    1.000000    1.000000    1.000000   \n",
              "75%     9775.000000    5.300000    1.000000    1.000000    1.000000   \n",
              "max    26400.000000    8.000000    1.000000    1.000000    1.000000   \n",
              "\n",
              "            appet          pe         ane  classification  \n",
              "count  262.000000  262.000000  262.000000      262.000000  \n",
              "mean     0.229008    0.812977    0.854962        0.381679  \n",
              "std      0.420998    0.390676    0.352813        0.486728  \n",
              "min      0.000000    0.000000    0.000000        0.000000  \n",
              "25%      0.000000    1.000000    1.000000        0.000000  \n",
              "50%      0.000000    1.000000    1.000000        0.000000  \n",
              "75%      0.000000    1.000000    1.000000        1.000000  \n",
              "max      1.000000    1.000000    1.000000        1.000000  \n",
              "\n",
              "[8 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-99276675-b9bf-4f65-aba0-6bd681ce8bd2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bp</th>\n",
              "      <th>sg</th>\n",
              "      <th>al</th>\n",
              "      <th>su</th>\n",
              "      <th>rbc</th>\n",
              "      <th>pc</th>\n",
              "      <th>pcc</th>\n",
              "      <th>ba</th>\n",
              "      <th>bgr</th>\n",
              "      <th>...</th>\n",
              "      <th>pcv</th>\n",
              "      <th>wc</th>\n",
              "      <th>rc</th>\n",
              "      <th>htn</th>\n",
              "      <th>dm</th>\n",
              "      <th>cad</th>\n",
              "      <th>appet</th>\n",
              "      <th>pe</th>\n",
              "      <th>ane</th>\n",
              "      <th>classification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>262.000000</td>\n",
              "      <td>262.000000</td>\n",
              "      <td>262.000000</td>\n",
              "      <td>262.000000</td>\n",
              "      <td>262.000000</td>\n",
              "      <td>262.000000</td>\n",
              "      <td>262.000000</td>\n",
              "      <td>262.000000</td>\n",
              "      <td>262.000000</td>\n",
              "      <td>262.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>262.00000</td>\n",
              "      <td>262.000000</td>\n",
              "      <td>262.000000</td>\n",
              "      <td>262.000000</td>\n",
              "      <td>262.000000</td>\n",
              "      <td>262.000000</td>\n",
              "      <td>262.000000</td>\n",
              "      <td>262.000000</td>\n",
              "      <td>262.000000</td>\n",
              "      <td>262.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>52.351145</td>\n",
              "      <td>76.259542</td>\n",
              "      <td>1.017338</td>\n",
              "      <td>0.998092</td>\n",
              "      <td>0.496183</td>\n",
              "      <td>0.835878</td>\n",
              "      <td>0.244275</td>\n",
              "      <td>0.900763</td>\n",
              "      <td>0.938931</td>\n",
              "      <td>155.921756</td>\n",
              "      <td>...</td>\n",
              "      <td>39.51145</td>\n",
              "      <td>8279.198473</td>\n",
              "      <td>4.697328</td>\n",
              "      <td>0.625954</td>\n",
              "      <td>0.633588</td>\n",
              "      <td>0.912214</td>\n",
              "      <td>0.229008</td>\n",
              "      <td>0.812977</td>\n",
              "      <td>0.854962</td>\n",
              "      <td>0.381679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>16.570954</td>\n",
              "      <td>14.375153</td>\n",
              "      <td>0.005532</td>\n",
              "      <td>1.323598</td>\n",
              "      <td>1.060427</td>\n",
              "      <td>0.371095</td>\n",
              "      <td>0.430479</td>\n",
              "      <td>0.299552</td>\n",
              "      <td>0.239915</td>\n",
              "      <td>78.560435</td>\n",
              "      <td>...</td>\n",
              "      <td>8.32378</td>\n",
              "      <td>2835.242178</td>\n",
              "      <td>0.923995</td>\n",
              "      <td>0.484802</td>\n",
              "      <td>0.482746</td>\n",
              "      <td>0.283525</td>\n",
              "      <td>0.420998</td>\n",
              "      <td>0.390676</td>\n",
              "      <td>0.352813</td>\n",
              "      <td>0.486728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>1.005000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>9.00000</td>\n",
              "      <td>2200.000000</td>\n",
              "      <td>2.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>43.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>1.013125</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>103.250000</td>\n",
              "      <td>...</td>\n",
              "      <td>33.25000</td>\n",
              "      <td>6662.500000</td>\n",
              "      <td>4.062500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>55.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>1.017500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>127.250000</td>\n",
              "      <td>...</td>\n",
              "      <td>41.00000</td>\n",
              "      <td>7900.000000</td>\n",
              "      <td>4.800000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>65.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>1.020000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>177.500000</td>\n",
              "      <td>...</td>\n",
              "      <td>45.50000</td>\n",
              "      <td>9775.000000</td>\n",
              "      <td>5.300000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>90.000000</td>\n",
              "      <td>180.000000</td>\n",
              "      <td>1.025000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>490.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>54.00000</td>\n",
              "      <td>26400.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 25 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-99276675-b9bf-4f65-aba0-6bd681ce8bd2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-99276675-b9bf-4f65-aba0-6bd681ce8bd2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-99276675-b9bf-4f65-aba0-6bd681ce8bd2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import RobustScaler"
      ],
      "metadata": {
        "id": "ZS1PYVJSeqmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.drop(columns='classification',axis=1)\n",
        "Y=df['classification']\n",
        "# scaler=StandardScaler()\n",
        "# scaler=MinMaxScaler(feature_range=(0,1))   \n",
        "scaler = RobustScaler()  \n",
        "scaled_X=scaler.fit_transform(X)\n",
        "scaled_X=pd.DataFrame(scaled_X, columns=X.columns)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(scaled_X, Y, test_size=0.14,random_state =42)"
      ],
      "metadata": {
        "id": "OqxhnrHBg-KV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"scaler = MinMaxScaler(feature_range=(0,1))   \n",
        "# scaler = RobustScaler()  \n",
        "scaled_X = scaler.fit_transform(X)\n",
        "X = scaled_X\n",
        "print(X[:10])\n",
        "\n",
        "# Splitting into train and test data - 80% train, 20% test\n",
        "split_pct = int(0.8*len(X))\n",
        "train_X, test_X = X[:split_pct], X[split_pct:]\n",
        "train_Y, test_Y = Y[:split_pct], Y[split_pct:]\n",
        "print(\"\\n\\n\")\n",
        "print(train_X[:10])\"\"\""
      ],
      "metadata": {
        "id": "Ts9GVz2pf1Nu",
        "outputId": "d3b02d88-e014-44ef-d25b-9a0bfadd718b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'scaler = MinMaxScaler(feature_range=(0,1))   \\n# scaler = RobustScaler()  \\nscaled_X = scaler.fit_transform(X)\\nX = scaled_X\\nprint(X[:10])\\n\\n# Splitting into train and test data - 80% train, 20% test\\nsplit_pct = int(0.8*len(X))\\ntrain_X, test_X = X[:split_pct], X[split_pct:]\\ntrain_Y, test_Y = Y[:split_pct], Y[split_pct:]\\nprint(\"\\n\\n\")\\nprint(train_X[:10])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequential Model in Keras"
      ],
      "metadata": {
        "id": "FaAsljI5hJCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "jEVODDOwf-wJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Dense(8,input_dim=len(X_train.columns),activation='relu'))\n",
        "model.add(Dense(4,activation='relu')) # y = max(0, x)\n",
        "#model.add(Dense(4,activation='relu'))\n",
        "model.add(Dense(1,activation='sigmoid'))  # y = 1 / 1+e^ -z"
      ],
      "metadata": {
        "id": "0apK8HHugCnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "buZDzTaxgDK_",
        "outputId": "d5577594-4a80-481a-fe16-12936e983f20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_27 (Dense)            (None, 8)                 200       \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 4)                 36        \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 241\n",
            "Trainable params: 241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
        "# model.compile(loss='binary_crossentropy',optimizer=Adam(learning_rate=0.0001),metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Xlh84uejgFkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=X_train,y=Y_train,epochs=256,verbose=1)"
      ],
      "metadata": {
        "id": "AHRvoUckgHnn",
        "outputId": "cb4e3bb0-d90e-4d32-bc54-a61e275e869d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/256\n",
            "8/8 [==============================] - 1s 2ms/step - loss: 0.6276 - accuracy: 0.5867\n",
            "Epoch 2/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5959 - accuracy: 0.6444\n",
            "Epoch 3/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5707 - accuracy: 0.6533\n",
            "Epoch 4/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.6444\n",
            "Epoch 5/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.6622\n",
            "Epoch 6/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.6800\n",
            "Epoch 7/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7022\n",
            "Epoch 8/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7244\n",
            "Epoch 9/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.7422\n",
            "Epoch 10/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7511\n",
            "Epoch 11/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4468 - accuracy: 0.7600\n",
            "Epoch 12/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7600\n",
            "Epoch 13/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.7733\n",
            "Epoch 14/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4111 - accuracy: 0.7867\n",
            "Epoch 15/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3995 - accuracy: 0.8178\n",
            "Epoch 16/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8311\n",
            "Epoch 17/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3807 - accuracy: 0.8356\n",
            "Epoch 18/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3714 - accuracy: 0.8356\n",
            "Epoch 19/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8489\n",
            "Epoch 20/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3542 - accuracy: 0.8667\n",
            "Epoch 21/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3450 - accuracy: 0.8933\n",
            "Epoch 22/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.9022\n",
            "Epoch 23/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3263 - accuracy: 0.9067\n",
            "Epoch 24/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.9244\n",
            "Epoch 25/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.9289\n",
            "Epoch 26/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3029 - accuracy: 0.9333\n",
            "Epoch 27/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2967 - accuracy: 0.9333\n",
            "Epoch 28/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2892 - accuracy: 0.9422\n",
            "Epoch 29/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2832 - accuracy: 0.9422\n",
            "Epoch 30/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2770 - accuracy: 0.9422\n",
            "Epoch 31/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2689 - accuracy: 0.9422\n",
            "Epoch 32/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2613 - accuracy: 0.9467\n",
            "Epoch 33/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2535 - accuracy: 0.9511\n",
            "Epoch 34/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.9511\n",
            "Epoch 35/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2375 - accuracy: 0.9511\n",
            "Epoch 36/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2289 - accuracy: 0.9556\n",
            "Epoch 37/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2216 - accuracy: 0.9600\n",
            "Epoch 38/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2147 - accuracy: 0.9600\n",
            "Epoch 39/256\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2073 - accuracy: 0.9600\n",
            "Epoch 40/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2001 - accuracy: 0.9600\n",
            "Epoch 41/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1945 - accuracy: 0.9600\n",
            "Epoch 42/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1886 - accuracy: 0.9600\n",
            "Epoch 43/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.9644\n",
            "Epoch 44/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.9644\n",
            "Epoch 45/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1723 - accuracy: 0.9600\n",
            "Epoch 46/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1678 - accuracy: 0.9644\n",
            "Epoch 47/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1635 - accuracy: 0.9600\n",
            "Epoch 48/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1594 - accuracy: 0.9644\n",
            "Epoch 49/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1543 - accuracy: 0.9644\n",
            "Epoch 50/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1501 - accuracy: 0.9644\n",
            "Epoch 51/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1452 - accuracy: 0.9644\n",
            "Epoch 52/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1403 - accuracy: 0.9644\n",
            "Epoch 53/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1360 - accuracy: 0.9644\n",
            "Epoch 54/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1319 - accuracy: 0.9644\n",
            "Epoch 55/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1285 - accuracy: 0.9644\n",
            "Epoch 56/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1247 - accuracy: 0.9644\n",
            "Epoch 57/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1205 - accuracy: 0.9644\n",
            "Epoch 58/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1173 - accuracy: 0.9644\n",
            "Epoch 59/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1139 - accuracy: 0.9644\n",
            "Epoch 60/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1100 - accuracy: 0.9644\n",
            "Epoch 61/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1066 - accuracy: 0.9644\n",
            "Epoch 62/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1035 - accuracy: 0.9644\n",
            "Epoch 63/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1006 - accuracy: 0.9644\n",
            "Epoch 64/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0975 - accuracy: 0.9644\n",
            "Epoch 65/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0946 - accuracy: 0.9689\n",
            "Epoch 66/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0919 - accuracy: 0.9689\n",
            "Epoch 67/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0898 - accuracy: 0.9689\n",
            "Epoch 68/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0878 - accuracy: 0.9689\n",
            "Epoch 69/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0863 - accuracy: 0.9689\n",
            "Epoch 70/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0844 - accuracy: 0.9689\n",
            "Epoch 71/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0818 - accuracy: 0.9689\n",
            "Epoch 72/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0797 - accuracy: 0.9689\n",
            "Epoch 73/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0771 - accuracy: 0.9689\n",
            "Epoch 74/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0748 - accuracy: 0.9689\n",
            "Epoch 75/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0728 - accuracy: 0.9689\n",
            "Epoch 76/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0708 - accuracy: 0.9689\n",
            "Epoch 77/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0689 - accuracy: 0.9689\n",
            "Epoch 78/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 0.9778\n",
            "Epoch 79/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 0.9778\n",
            "Epoch 80/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.9778\n",
            "Epoch 81/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 0.9778\n",
            "Epoch 82/256\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.9778\n",
            "Epoch 83/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0596 - accuracy: 0.9778\n",
            "Epoch 84/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.9822\n",
            "Epoch 85/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0565 - accuracy: 0.9822\n",
            "Epoch 86/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0549 - accuracy: 0.9822\n",
            "Epoch 87/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0531 - accuracy: 0.9822\n",
            "Epoch 88/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9822\n",
            "Epoch 89/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0502 - accuracy: 0.9822\n",
            "Epoch 90/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0486 - accuracy: 0.9822\n",
            "Epoch 91/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0476 - accuracy: 0.9911\n",
            "Epoch 92/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0465 - accuracy: 0.9867\n",
            "Epoch 93/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0453 - accuracy: 0.9911\n",
            "Epoch 94/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.9911\n",
            "Epoch 95/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0425 - accuracy: 0.9911\n",
            "Epoch 96/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0410 - accuracy: 0.9911\n",
            "Epoch 97/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9911\n",
            "Epoch 98/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0382 - accuracy: 0.9911\n",
            "Epoch 99/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.9911\n",
            "Epoch 100/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0360 - accuracy: 0.9911\n",
            "Epoch 101/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.9911\n",
            "Epoch 102/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 0.9911\n",
            "Epoch 103/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.9911\n",
            "Epoch 104/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 0.9911\n",
            "Epoch 105/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 0.9911\n",
            "Epoch 106/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0295 - accuracy: 0.9911\n",
            "Epoch 107/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 0.9911\n",
            "Epoch 108/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 0.9911\n",
            "Epoch 109/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 0.9911\n",
            "Epoch 110/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0264 - accuracy: 0.9911\n",
            "Epoch 111/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0258 - accuracy: 0.9911\n",
            "Epoch 112/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0254 - accuracy: 0.9911\n",
            "Epoch 113/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0246 - accuracy: 0.9911\n",
            "Epoch 114/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0239 - accuracy: 0.9911\n",
            "Epoch 115/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0235 - accuracy: 0.9911\n",
            "Epoch 116/256\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0230 - accuracy: 0.9911\n",
            "Epoch 117/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0223 - accuracy: 0.9911\n",
            "Epoch 118/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 0.9911\n",
            "Epoch 119/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 0.9911\n",
            "Epoch 120/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0206 - accuracy: 0.9956\n",
            "Epoch 121/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 0.9911\n",
            "Epoch 122/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 0.9956\n",
            "Epoch 123/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 0.9956\n",
            "Epoch 124/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0175 - accuracy: 0.9956\n",
            "Epoch 125/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 0.9956\n",
            "Epoch 126/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9956\n",
            "Epoch 127/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 1.0000\n",
            "Epoch 128/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 1.0000\n",
            "Epoch 129/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0137 - accuracy: 1.0000\n",
            "Epoch 130/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0132 - accuracy: 1.0000\n",
            "Epoch 131/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 1.0000\n",
            "Epoch 132/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 1.0000\n",
            "Epoch 133/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 1.0000\n",
            "Epoch 134/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0108 - accuracy: 1.0000\n",
            "Epoch 135/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 1.0000\n",
            "Epoch 136/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 1.0000\n",
            "Epoch 137/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 1.0000\n",
            "Epoch 138/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 1.0000\n",
            "Epoch 139/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 1.0000\n",
            "Epoch 140/256\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 1.0000\n",
            "Epoch 141/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 1.0000\n",
            "Epoch 142/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 1.0000\n",
            "Epoch 143/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 1.0000\n",
            "Epoch 144/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 145/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 1.0000\n",
            "Epoch 146/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 1.0000\n",
            "Epoch 147/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 148/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000\n",
            "Epoch 149/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 1.0000\n",
            "Epoch 150/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 151/256\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000\n",
            "Epoch 152/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 153/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000\n",
            "Epoch 154/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 155/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000\n",
            "Epoch 156/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 157/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 158/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 159/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 160/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 161/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 162/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 163/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 164/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 165/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 166/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 167/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 168/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 169/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 170/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 171/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 172/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 173/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 174/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 175/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 176/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 177/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 178/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 179/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 9.5352e-04 - accuracy: 1.0000\n",
            "Epoch 180/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.0739e-04 - accuracy: 1.0000\n",
            "Epoch 181/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 8.4324e-04 - accuracy: 1.0000\n",
            "Epoch 182/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 7.8821e-04 - accuracy: 1.0000\n",
            "Epoch 183/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.4760e-04 - accuracy: 1.0000\n",
            "Epoch 184/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.9568e-04 - accuracy: 1.0000\n",
            "Epoch 185/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.4839e-04 - accuracy: 1.0000\n",
            "Epoch 186/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.1465e-04 - accuracy: 1.0000\n",
            "Epoch 187/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6107e-04 - accuracy: 1.0000\n",
            "Epoch 188/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.3742e-04 - accuracy: 1.0000\n",
            "Epoch 189/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.9514e-04 - accuracy: 1.0000\n",
            "Epoch 190/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.6433e-04 - accuracy: 1.0000\n",
            "Epoch 191/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.4121e-04 - accuracy: 1.0000\n",
            "Epoch 192/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.1057e-04 - accuracy: 1.0000\n",
            "Epoch 193/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.8835e-04 - accuracy: 1.0000\n",
            "Epoch 194/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.6405e-04 - accuracy: 1.0000\n",
            "Epoch 195/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.3407e-04 - accuracy: 1.0000\n",
            "Epoch 196/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.0847e-04 - accuracy: 1.0000\n",
            "Epoch 197/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.8888e-04 - accuracy: 1.0000\n",
            "Epoch 198/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.7040e-04 - accuracy: 1.0000\n",
            "Epoch 199/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.4896e-04 - accuracy: 1.0000\n",
            "Epoch 200/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.3757e-04 - accuracy: 1.0000\n",
            "Epoch 201/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.1433e-04 - accuracy: 1.0000\n",
            "Epoch 202/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.0201e-04 - accuracy: 1.0000\n",
            "Epoch 203/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.8766e-04 - accuracy: 1.0000\n",
            "Epoch 204/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7479e-04 - accuracy: 1.0000\n",
            "Epoch 205/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.6340e-04 - accuracy: 1.0000\n",
            "Epoch 206/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5165e-04 - accuracy: 1.0000\n",
            "Epoch 207/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3962e-04 - accuracy: 1.0000\n",
            "Epoch 208/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3196e-04 - accuracy: 1.0000\n",
            "Epoch 209/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.2156e-04 - accuracy: 1.0000\n",
            "Epoch 210/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1208e-04 - accuracy: 1.0000\n",
            "Epoch 211/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.0423e-04 - accuracy: 1.0000\n",
            "Epoch 212/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.7784e-05 - accuracy: 1.0000\n",
            "Epoch 213/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.9404e-05 - accuracy: 1.0000\n",
            "Epoch 214/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.3653e-05 - accuracy: 1.0000\n",
            "Epoch 215/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 7.8696e-05 - accuracy: 1.0000\n",
            "Epoch 216/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.2931e-05 - accuracy: 1.0000\n",
            "Epoch 217/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.7906e-05 - accuracy: 1.0000\n",
            "Epoch 218/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.2798e-05 - accuracy: 1.0000\n",
            "Epoch 219/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.9064e-05 - accuracy: 1.0000\n",
            "Epoch 220/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.3583e-05 - accuracy: 1.0000\n",
            "Epoch 221/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.9936e-05 - accuracy: 1.0000\n",
            "Epoch 222/256\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.5433e-05 - accuracy: 1.0000\n",
            "Epoch 223/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.2379e-05 - accuracy: 1.0000\n",
            "Epoch 224/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.8122e-05 - accuracy: 1.0000\n",
            "Epoch 225/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.5842e-05 - accuracy: 1.0000\n",
            "Epoch 226/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.3023e-05 - accuracy: 1.0000\n",
            "Epoch 227/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.0038e-05 - accuracy: 1.0000\n",
            "Epoch 228/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.8427e-05 - accuracy: 1.0000\n",
            "Epoch 229/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.5593e-05 - accuracy: 1.0000\n",
            "Epoch 230/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.4055e-05 - accuracy: 1.0000\n",
            "Epoch 231/256\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1920e-05 - accuracy: 1.0000\n",
            "Epoch 232/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.0253e-05 - accuracy: 1.0000\n",
            "Epoch 233/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.8387e-05 - accuracy: 1.0000\n",
            "Epoch 234/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7025e-05 - accuracy: 1.0000\n",
            "Epoch 235/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5452e-05 - accuracy: 1.0000\n",
            "Epoch 236/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4148e-05 - accuracy: 1.0000\n",
            "Epoch 237/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.2863e-05 - accuracy: 1.0000\n",
            "Epoch 238/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.2053e-05 - accuracy: 1.0000\n",
            "Epoch 239/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.0860e-05 - accuracy: 1.0000\n",
            "Epoch 240/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 9.7263e-06 - accuracy: 1.0000\n",
            "Epoch 241/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 9.1385e-06 - accuracy: 1.0000\n",
            "Epoch 242/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 8.1576e-06 - accuracy: 1.0000\n",
            "Epoch 243/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.5444e-06 - accuracy: 1.0000\n",
            "Epoch 244/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.8368e-06 - accuracy: 1.0000\n",
            "Epoch 245/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.2108e-06 - accuracy: 1.0000\n",
            "Epoch 246/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.8196e-06 - accuracy: 1.0000\n",
            "Epoch 247/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.2360e-06 - accuracy: 1.0000\n",
            "Epoch 248/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.7911e-06 - accuracy: 1.0000\n",
            "Epoch 249/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.2278e-06 - accuracy: 1.0000\n",
            "Epoch 250/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.9584e-06 - accuracy: 1.0000\n",
            "Epoch 251/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.6375e-06 - accuracy: 1.0000\n",
            "Epoch 252/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4573e-06 - accuracy: 1.0000\n",
            "Epoch 253/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.0838e-06 - accuracy: 1.0000\n",
            "Epoch 254/256\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.8660e-06 - accuracy: 1.0000\n",
            "Epoch 255/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.5874e-06 - accuracy: 1.0000\n",
            "Epoch 256/256\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.3632e-06 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f77e441a510>"
            ]
          },
          "metadata": {},
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicts = model.predict(X_test)"
      ],
      "metadata": {
        "id": "C_mmYrfZgJs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Less than 0.5, No. More than 0.5, Yes.\n",
        "predicts = predicts.round()"
      ],
      "metadata": {
        "id": "9bDfkF3u8RBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_result(data):\n",
        "  df = pd.DataFrame((np.array(data)).reshape(1,-1), columns=X_train.columns)\n",
        "  standard_data=scaler.transform(df)\n",
        "  df = pd.DataFrame(standard_data, columns=X_train.columns)\n",
        "  predict=model.predict(df)\n",
        "  if predict==0:\n",
        "    print(\"You are healthy\")\n",
        "  else:\n",
        "    print(\"You are suffering from Chronic Kidney Disease\")"
      ],
      "metadata": {
        "id": "FJCKnZ9o8REh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=[65,75,1.010,3,0,0,1,0,1,122,42,1.7,136,4.7,12.6,45,7900,2.8,0,0,1,0,1,1]\n",
        "print_result(data)\n",
        "data=[75,75,1.025,3,0,1,1,0,1,128,43,280,128,4,12.6,50,10000,2.8,1,0,1,0,1,1]\n",
        "print_result(data)"
      ],
      "metadata": {
        "id": "mhSGWoES8Udf",
        "outputId": "37dbd8d6-fc48-42c4-e852-f45a71c0cd13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are suffering from Chronic Kidney Disease\n",
            "You are healthy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score,recall_score,accuracy_score,f1_score\n",
        "print('Precision: %.3f' % precision_score(Y_test,predicts))\n",
        "print('Recall: %.3f' % recall_score(Y_test, predicts))\n",
        "print('Accuracy: %.3f' % accuracy_score(Y_test, predicts))\n",
        "print('F1-Score: %.3f' % f1_score(Y_test, predicts))"
      ],
      "metadata": {
        "id": "1AcCkdib8Uf-",
        "outputId": "4d82a261-bb3e-46e5-fb14-a864bd4f516b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 1.000\n",
            "Recall: 1.000\n",
            "Accuracy: 1.000\n",
            "F1-Score: 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "ConfusionMatrixDisplay.from_predictions(Y_test, predicts.round())"
      ],
      "metadata": {
        "id": "PPNBe3aj8UiW",
        "outputId": "899d8ffe-e924-4420-debf-7cca8e439c4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f77e424a950>"
            ]
          },
          "metadata": {},
          "execution_count": 220
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}